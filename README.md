# Abstract
The modern digital landscape is witnessing an exponential increase in multimedia 
content, creating significant challenges in its effective management. As traditional 
methods for organizing and retrieving audiovisual content become increasingly 
inadequate, there is an urgent need for an online application that incorporates 
advanced processing and search capabilities. The aim of this thesis is to develop an 
online environment for improving the management, retrieval, semantic processing, 
and recognition of audiovisual content. The proposed system incorporates advanced 
artificial intelligence algorithms for speech-to-text conversion, combined with named 
entity recognition for topic extraction, thereby enhancing the search and retrieval of 
multimedia content. Additionally, an action recognition algorithm and an audio 
classification algorithm that utilizes wavelet-based spectrograms to represent the 
audio signal with high accuracy are employed. By combining these technologies, the 
system surpasses traditional metadata dependent approaches, providing a robust and 
semantically enriched environment that can be utilized by both experienced and 
novice users. The system has been designed to be easily expandable and capable of 
managing large volumes of data, employing an architecture for asynchronous 
communication and processing supported by the tools RabbitMQ and Celery. Primarily 
targeting the university community, the application not only enhances the accessibility 
and retrieval of audiovisual content but also promotes innovation and research by 
offering a unified platform that can be extended in various ways.
